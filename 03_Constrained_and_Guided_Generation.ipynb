{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwunfRWGCc/TPOgypvsLSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarChalcoElias/prompting-techniques/blob/main/03_Constrained_and_Guided_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constrained and Guided Generation"
      ],
      "metadata": {
        "id": "ga907Hn9OZ9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Overview**  \n",
        "This tutorial explores the concepts of constrained and guided generation in the context of large language models. We'll focus on techniques to set up constraints for model outputs and implement rule-based generation using OpenAI's GPT models and the LangChain library.\n",
        "\n",
        "### **Motivation**  \n",
        "While large language models are powerful tools for generating text, they sometimes produce outputs that are too open-ended or lack specific desired characteristics. Constrained and guided generation techniques allow us to exert more control over the model's outputs, making them more suitable for specific tasks or adhering to certain rules and formats."
      ],
      "metadata": {
        "id": "twLmbTZIOjUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "t88ohSXHJvSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai langchain-core -q"
      ],
      "metadata": {
        "id": "3635QRHCJqnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b0026a-ac6c-46c9-bc34-2848fa0b3708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/484.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imxlr2mlG52M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Vo-CblrFKivg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-5-nano\")"
      ],
      "metadata": {
        "id": "mkAvncRfKBbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display model outputs\n",
        "def display_output(output):\n",
        "    \"\"\"Display the model's output in a formatted manner.\"\"\"\n",
        "    print(\"Model Output:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(output)\n",
        "    print(\"-\" * 40)\n",
        "    print()"
      ],
      "metadata": {
        "id": "aSgqE3ATkgem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Constraints for Model Outputs"
      ],
      "metadata": {
        "id": "HfB3nSaGjBh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "constrained_prompt = PromptTemplate(\n",
        "    input_variables=[\"product\", \"target_audience\", \"tone\", \"word_limit\"],\n",
        "    template=\"\"\"Create a product description for {product} targeted at {target_audience}.\n",
        "    Use a {tone} tone and keep it under {word_limit} words.\n",
        "    The description should include:\n",
        "    1. A catchy headline\n",
        "    2. Three key features\n",
        "    3. A call to action\n",
        "\n",
        "    Product Description:\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "lQ2Sqp35jDBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_variables = {\n",
        "    \"product\": \"smart water bottle\",\n",
        "    \"target_audience\": \"health-conscious millennials\",\n",
        "    \"tone\": \"casual and friendly\",\n",
        "    \"word_limit\": \"75\"\n",
        "}"
      ],
      "metadata": {
        "id": "4GH885qPjC_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = constrained_prompt | llm\n",
        "output = chain.invoke(input_variables).content\n",
        "display_output(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuUMo-AmjC81",
        "outputId": "47e74076-09f2-4eb3-d284-4716d452fab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Output:\n",
            "----------------------------------------\n",
            "Sip Smart. Live Well.\n",
            "\n",
            "- Real-time hydration reminders and in-app tracking\n",
            "- Temperature control with a durable, BPA-free design\n",
            "- UV-C self-clean mode for effortless freshness\n",
            "\n",
            "Grab yours and upgrade your hydration today.\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Rule-Based Generation"
      ],
      "metadata": {
        "id": "x4shN2uImfbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_posting_prompt = PromptTemplate(\n",
        "    input_variables=[\"job_title\", \"company\", \"location\", \"experience\"],\n",
        "    template=\"\"\"Create a job posting for a {job_title} position at {company} in {location}.\n",
        "    The candidate should have {experience} years of experience.\n",
        "    Follow these rules:\n",
        "    1. Start with a brief company description (2 sentences)\n",
        "    2. List 5 key responsibilities, each starting with an action verb\n",
        "    3. List 5 required qualifications, each in a single sentence\n",
        "    4. End with a standardized equal opportunity statement\n",
        "\n",
        "    Format the output as follows:\n",
        "    COMPANY: [Company Description]\n",
        "\n",
        "    RESPONSIBILITIES:\n",
        "    - [Responsibility 1]\n",
        "    - [Responsibility 2]\n",
        "    - [Responsibility 3]\n",
        "    - [Responsibility 4]\n",
        "    - [Responsibility 5]\n",
        "\n",
        "    QUALIFICATIONS:\n",
        "    - [Qualification 1]\n",
        "    - [Qualification 2]\n",
        "    - [Qualification 3]\n",
        "    - [Qualification 4]\n",
        "    - [Qualification 5]\n",
        "\n",
        "    EEO: [Equal Opportunity Statement]\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "R5VpGDkOi_EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the rule-based output\n",
        "input_variables = {\n",
        "    \"job_title\": \"Staff AI Engineer\",\n",
        "    \"company\": \"Deloitte Chile\",\n",
        "    \"location\": \"Santiago, Chile\",\n",
        "    \"experience\": \"5+\"\n",
        "}"
      ],
      "metadata": {
        "id": "QA550fthnFr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = job_posting_prompt | llm\n",
        "output = chain.invoke(input_variables).content\n",
        "display_output(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKSesXxHnFls",
        "outputId": "e7554e1d-d1fc-4795-8e8e-9986f150da76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Output:\n",
            "----------------------------------------\n",
            "COMPANY: Based in Santiago, Deloitte Chile is a leading professional services firm delivering audit, consulting, tax, and advisory services across Chile. We are seeking a Staff AI Engineer to join our team and accelerate AI-driven initiatives for clients.\n",
            "\n",
            "RESPONSIBILITIES:\n",
            "- Lead the end-to-end design, development, and deployment of AI/ML solutions for client engagements.\n",
            "- Architect scalable AI systems and data pipelines on cloud platforms aligned with security and governance requirements.\n",
            "- Collaborate with product, data, and business teams to translate requirements into robust ML models and deployment plans.\n",
            "- Mentor and coach junior engineers, promoting best practices in MLops, model governance, and responsible AI.\n",
            "- Ensure successful delivery by conducting code reviews, implementing automated tests, and upholding Deloitte's engineering standards.\n",
            "\n",
            "QUALIFICATIONS:\n",
            "- Have at least 5 years of hands-on experience in AI/ML engineering, with a track record delivering production-grade models.\n",
            "- Possess deep expertise in Python and ML frameworks (TensorFlow, PyTorch, scikit-learn) and experience with MLOps tools.\n",
            "- Show strong knowledge of cloud platforms (AWS, GCP, or Azure) and data engineering concepts.\n",
            "- Demonstrate experience with model governance, ethics, and responsible AI practices, including bias detection and explainability.\n",
            "- Exhibit excellent communication skills in Spanish and English, with the ability to translate technical concepts for non-technical stakeholders.\n",
            "\n",
            "EEO: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. Deloitte is an equal opportunity employer and we value diversity in our workforce.\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using JSON Parser for Structured Output"
      ],
      "metadata": {
        "id": "V4T_UrCWstCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser"
      ],
      "metadata": {
        "id": "0QGdGZfNsyHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JobPosting(BaseModel):\n",
        "    company_description: str = Field(description=\"The company's description.\")\n",
        "    role: str = Field(description=\"The job role.\")\n",
        "    job_description: str = Field(description=\"The job description.\")\n",
        "    responsibilities: list[str] = Field(description=\"The company's responsibilities.\")\n",
        "    qualifications: list[str] = Field(description=\"The company's qualifications.\")\n",
        "    eeo_statement: str = Field(description=\"The equal opportunity statement.\")"
      ],
      "metadata": {
        "id": "GHo4Iha5tC4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_parser = JsonOutputParser(\n",
        "    pydantic_object=JobPosting,\n",
        "    allow_multi_json=True\n",
        ")"
      ],
      "metadata": {
        "id": "UoIRAzypnDcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new prompt template that includes the parser instructions\n",
        "parsed_job_posting_prompt = PromptTemplate(\n",
        "    input_variables=[\"job_title\", \"company\", \"location\", \"experience\"],\n",
        "    template=\"\"\"Create a job posting in JSON format for a {job_title} position at {company} in {location}.\n",
        "The role requires {experience} years of experience.\n",
        "\n",
        "You MUST return a single valid JSON object and NOTHING else.\n",
        "Do not include explanations, markdown, or extra text.\n",
        "\n",
        "The JSON must follow these rules:\n",
        "\n",
        "- \"company_description\": a brief description of the company in exactly 2 sentences.\n",
        "- \"role\": the job title.\n",
        "- \"job_description\": a concise paragraph describing the role and its purpose.\n",
        "- \"responsibilities\": an array of exactly 5 items.\n",
        "  - Each item must start with an action verb.\n",
        "- \"qualifications\": an array of exactly 5 items.\n",
        "  - Each item must be a single sentence.\n",
        "- \"eeo_statement\": a standardized equal opportunity employment statement.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "YeJKq9UGtq9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_output(output):\n",
        "    for key, value in output.items():\n",
        "        if isinstance(value, str):\n",
        "            # Remove leading/trailing whitespace and normalize newlines\n",
        "            output[key] = re.sub(r'\\n\\s*', '\\n', value.strip())\n",
        "    return output"
      ],
      "metadata": {
        "id": "dc2ckjw9thRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the parsed output\n",
        "chain = parsed_job_posting_prompt | llm\n",
        "raw_output = chain.invoke(input_variables).content"
      ],
      "metadata": {
        "id": "jHJFwD9ztlTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Use with_structured_output for robust JSON parsing\n",
        "structured_llm = llm.with_structured_output(JobPosting)\n",
        "\n",
        "# Create the chain\n",
        "chain = parsed_job_posting_prompt | structured_llm\n",
        "\n",
        "# Invoke the chain, the output will now be a JobPosting Pydantic object\n",
        "parsed_output_pydantic = chain.invoke(input_variables)\n",
        "\n",
        "# Convert the Pydantic object to a dictionary before cleaning,\n",
        "# using .model_dump() for Pydantic V2 compatibility or .dict() for V1.\n",
        "parsed_output_dict = parsed_output_pydantic.model_dump()\n",
        "\n",
        "# Clean the output\n",
        "cleaned_output = clean_output(parsed_output_dict)"
      ],
      "metadata": {
        "id": "UgKM-BhAtnQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the parsed output\n",
        "print(\"Parsed Output:\")\n",
        "for key, value in cleaned_output.items():\n",
        "    print(f\"{key.upper()}:\")\n",
        "    print(value)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylmhp3Qht3I7",
        "outputId": "2a65a9c8-8b04-45d7-ff9b-93de532286f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed Output:\n",
            "COMPANY_DESCRIPTION:\n",
            "Deloitte is a leading professional services firm providing audit, consulting, financial advisory, risk management, and tax services. In Chile, we serve clients across industries with a focus on innovative solutions and technology-enabled transformations.\n",
            "\n",
            "ROLE:\n",
            "Staff AI Engineer\n",
            "\n",
            "JOB_DESCRIPTION:\n",
            "As a Staff AI Engineer at Deloitte Chile, you will lead the design, development, and deployment of AI and data-driven solutions that address client challenges. You will collaborate with cross-functional teams to translate business needs into scalable AI architectures, ensure compliance with local regulations, and mentor junior engineers.\n",
            "\n",
            "RESPONSIBILITIES:\n",
            "['Design and implement AI models and pipelines that deliver measurable business impact.', 'Architect scalable machine learning solutions, including data ingestion, feature engineering, and model deployment.', 'Collaborate with data engineers, product managers, and client teams to translate business requirements into technical specifications.', 'Lead code reviews and mentor junior engineers to promote best practices in software development and MLOps.', 'Evaluate emerging AI technologies and drive proof-of-concept initiatives to de-risk and validate approaches.']\n",
            "\n",
            "QUALIFICATIONS:\n",
            "['Minimum of 5 years of hands-on experience in AI/ML model development, deployment, and production monitoring.', 'Proficiency in Python and ML frameworks such as TensorFlow or PyTorch, with experience in cloud environments (AWS, Azure, or GCP).', 'Strong knowledge of data engineering concepts, ETL processes, and data governance.', \"Bachelor's or master's degree in Computer Science, Engineering, or a related field.\", 'Excellent communication skills in Spanish and English, with the ability to explain complex technical concepts to non-technical stakeholders.']\n",
            "\n",
            "EEO_STATEMENT:\n",
            "Deloitte is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, or any other characteristic protected by law.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "### Trade-offs\n",
        "\n",
        "#### Guided generation\n",
        "- Usually achieves very strong performance with minimal engineering effort, but does **not guarantee** structural correctness.\n",
        "- Cheaper and faster than constrained approaches since generation happens once and without decoder-level restrictions.\n",
        "- Still prone to format violations, hallucinated fields, or partial schema compliance.\n",
        "- Requires retries, repair logic, or fallback handling in production systems.\n",
        "- Behavior depends heavily on prompt quality and model alignment.\n",
        "\n",
        "#### Constrained generation\n",
        "- Guarantees structural correctness by preventing invalid tokens at decoding time.\n",
        "- More reliable for automation and system-to-system communication.\n",
        "- Can reduce model expressiveness and sometimes degrade semantic quality.\n",
        "- More complex to implement and often backend- or model-dependent.\n",
        "- May increase latency due to constrained decoding logic.\n",
        "\n",
        "---\n",
        "\n",
        "### When to apply it\n",
        "\n",
        "#### Guided generation\n",
        "- When schemas are flexible or evolving.\n",
        "- When human review is involved downstream.\n",
        "- For reasoning-heavy, analytical, or explanatory outputs.\n",
        "- When occasional retries or fixes are acceptable.\n",
        "- During prototyping, experimentation, or rapid iteration.\n",
        "\n",
        "#### Constrained generation\n",
        "- When outputs feed directly into automated systems.\n",
        "- For tool invocation, workflow orchestration, or database writes.\n",
        "- When strict contracts are required (e.g., enums, IDs, commands).\n",
        "- At scale, where retries are costly or unacceptable.\n",
        "- When failure modes must be eliminated, not handled.\n",
        "\n",
        "---\n",
        "\n",
        "### When NOT to apply it\n",
        "\n",
        "#### Guided generation\n",
        "- When invalid structure can cause system failures.\n",
        "- For safety-critical or compliance-sensitive outputs.\n",
        "- When strict determinism is required.\n",
        "\n",
        "#### Constrained generation\n",
        "- For creative or open-ended tasks with no single ground truth.\n",
        "- When the schema is large, deeply nested, or frequently changing.\n",
        "- For tasks where guided generation already performs well.\n",
        "- When the added engineering complexity outweighs reliability gains.\n",
        "\n",
        "---\n",
        "\n",
        "### Clarifying terms\n",
        "\n",
        "- **Guided generation** means the model is *encouraged* via prompts or examples to follow a structure, but is still free to generate any token.\n",
        "- **Constrained generation** means the model is *restricted at decoding time* so invalid tokens cannot be generated at all.\n",
        "- **Parsers and validators do not constrain generation**; they only detect or repair errors after generation.\n",
        "- **Structured output APIs are not always truly constrained**; many rely on strong guidance plus retries under the hood.\n",
        "- The key distinction is **where control happens**:\n",
        "  - Prompt level → guided\n",
        "  - Post-generation validation → validation\n",
        "  - Decoder token selection → constrained\n"
      ],
      "metadata": {
        "id": "rbe49kBbAij0"
      }
    }
  ]
}